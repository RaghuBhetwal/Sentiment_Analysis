{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30fb0d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "import pandas as pd\n",
    "import googleapiclient.discovery\n",
    "from googleapiclient.errors import HttpError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a1f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-api-python-client #Library to interacts with Google APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec363ac",
   "metadata": {},
   "source": [
    "### Function to authenticate with the YouTube API using an API key\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6316e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_authenticated_service(api_key):\n",
    "    return googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d59be3c",
   "metadata": {},
   "source": [
    "# Function to retrieve comments for a YouTube video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1eec987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_comments(service, video_id, max_comments=1000):\n",
    "    comments = []\n",
    "    page_token = None\n",
    "\n",
    "    # Loop until the desired number of comments is reached\n",
    "    while len(comments) < max_comments:\n",
    "        kwargs = {\n",
    "            \"part\": \"snippet\",\n",
    "            \"videoId\": video_id,\n",
    "            \"textFormat\": \"plainText\",\n",
    "            \"order\": \"relevance\",\n",
    "            \"maxResults\": min(100, max_comments - len(comments)),\n",
    "        }\n",
    "\n",
    "        if page_token:\n",
    "            kwargs[\"pageToken\"] = page_token\n",
    "\n",
    "        try:\n",
    "            # Execute the API request to retrieve comments\n",
    "            results = service.commentThreads().list(**kwargs).execute()\n",
    "\n",
    "            # Extract comments from the API response\n",
    "            for item in results.get(\"items\", []):\n",
    "                comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "                comments.append(comment)\n",
    "\n",
    "            # Update the page token for pagination\n",
    "            page_token = results.get(\"nextPageToken\")\n",
    "\n",
    "            # Exit the loop if no more comments are available\n",
    "            if not page_token:\n",
    "                break\n",
    "\n",
    "        except HttpError as e:\n",
    "            # Handle HTTP errors and print an error message\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "    return comments[:max_comments]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2597c",
   "metadata": {},
   "source": [
    "### Main function to execute the YouTube comments retrieval and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b7801ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Set your YouTube API key here\n",
    "    API_KEY = \"AIzaSyBH-LQhuQMITV7p-Krarbnydkl8J1VhKck\"  # Replace with your actual API key\n",
    "\n",
    "    # Authenticate with YouTube API using the API key\n",
    "    service = get_authenticated_service(API_KEY)\n",
    "\n",
    "    # YouTube video ID: Lord of the rings Trailer\n",
    "    video_id = \"x8UAUAuKNcU\"  # Replace with the actual video ID\n",
    "\n",
    "    try:\n",
    "        # Get up to 1000 comments for the specified video\n",
    "        comments = get_video_comments(service, video_id, max_comments=1000)\n",
    "\n",
    "        # Convert comments to a pandas DataFrame\n",
    "        df = pd.DataFrame({\"Comments\": comments})\n",
    "\n",
    "        # Print the DataFrame\n",
    "        print(df)\n",
    "\n",
    "        # Save the DataFrame to a CSV file\n",
    "        csv_file_path = \"comments.csv\"\n",
    "        df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "        # Print a success message with the file path\n",
    "        print(f\"Comments saved to {csv_file_path}\")\n",
    "\n",
    "    except HttpError as e:\n",
    "        # Handle HTTP errors and print an error message\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf16b79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Comments\n",
      "0    â€œEvacuate the city, engage all defences and ge...\n",
      "1    Infinity War was such a legendary movie that p...\n",
      "2    The way MCU built up Thanos for 10 years is on...\n",
      "3    Infinity War was MCU peak. 5 years and still h...\n",
      "4    Itâ€™s almost 2024 and this trailer still puts a...\n",
      "..                                                 ...\n",
      "995                      humans and movies peaked here\n",
      "996                             It's been five years ðŸ˜¢\n",
      "997               1:59 is everything they took from us\n",
      "998  You can't live with your own failures, where d...\n",
      "999                    And now... Look at the Marvel ðŸ¤§\n",
      "\n",
      "[1000 rows x 1 columns]\n",
      "Comments saved to comments.csv\n"
     ]
    }
   ],
   "source": [
    "# Call the main function to execute the script\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1d40830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments saved to comments.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the comments DataFrame from the CSV file\n",
    "df = pd.read_csv(\"comments.csv\")\n",
    "\n",
    "# Saving the DataFrame to an Excel file\n",
    "excel_file_path = \"comments.xlsx\"\n",
    "df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f\"Comments saved to {excel_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e36e73f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from Excel:\n",
      "                                              Comments\n",
      "0    â€œEvacuate the city, engage all defences and ge...\n",
      "1    Infinity War was such a legendary movie that p...\n",
      "2    The way MCU built up Thanos for 10 years is on...\n",
      "3    Infinity War was MCU peak. 5 years and still h...\n",
      "4    Itâ€™s almost 2024 and this trailer still puts a...\n",
      "..                                                 ...\n",
      "995                      humans and movies peaked here\n",
      "996                             It's been five years ðŸ˜¢\n",
      "997               1:59 is everything they took from us\n",
      "998  You can't live with your own failures, where d...\n",
      "999                    And now... Look at the Marvel ðŸ¤§\n",
      "\n",
      "[1000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Loading the Excel file into a DataFrame\n",
    "excel_file_path = \"comments.xlsx\"\n",
    "df = pd.read_excel(excel_file_path)\n",
    "\n",
    "# Displaying the DataFrame\n",
    "print(\"DataFrame from Excel:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee78d0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>â€œEvacuate the city, engage all defences and ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Infinity War was such a legendary movie that p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Comments\n",
       "0  â€œEvacuate the city, engage all defences and ge...\n",
       "1  Infinity War was such a legendary movie that p..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)#Taking first 2 elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1100f8a1",
   "metadata": {},
   "source": [
    "# Comments from Multiple Videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0608401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "import pandas as pd\n",
    "import googleapiclient.discovery\n",
    "from googleapiclient.errors import HttpError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f155803",
   "metadata": {},
   "source": [
    "###  Function to authenticate with the YouTube API using an API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34eb50bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_authenticated_service(api_key):\n",
    "    return googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5767dd",
   "metadata": {},
   "source": [
    "### Function to retrieve comments for a YouTube video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5df781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_comments(service, video_id, remaining_comments):\n",
    "    comments = []\n",
    "    page_token = None\n",
    "\n",
    "    # Loop until the remaining number of comments is reached\n",
    "    while remaining_comments > 0:\n",
    "        # maxResults based on the remaining_comments\n",
    "        max_results = min(100, remaining_comments)\n",
    "\n",
    "        kwargs = {\n",
    "            \"part\": \"snippet\",\n",
    "            \"videoId\": video_id,\n",
    "            \"textFormat\": \"plainText\",\n",
    "            \"order\": \"relevance\",\n",
    "            \"maxResults\": max_results,\n",
    "        }\n",
    "\n",
    "        if page_token:\n",
    "            kwargs[\"pageToken\"] = page_token\n",
    "\n",
    "        try:\n",
    "            # API request to retrieve comments\n",
    "            results = service.commentThreads().list(**kwargs).execute()\n",
    "\n",
    "            # comments from the API response\n",
    "            for item in results.get(\"items\", []):\n",
    "                comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "                comments.append(comment)\n",
    "\n",
    "            # Updating page token for pagination\n",
    "            page_token = results.get(\"nextPageToken\")\n",
    "\n",
    "            # Exit the loop if no more comments are available\n",
    "            if not page_token:\n",
    "                break\n",
    "                \n",
    "    # Handles HTTP errors and print an error message\n",
    "        except HttpError as e:           \n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "        # Update the remaining number of comments\n",
    "        remaining_comments -= max_results\n",
    "\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d68a41c",
   "metadata": {},
   "source": [
    "###  Main function to execute the YouTube comments retrieval and processing for multiple videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "818c0c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Set your YouTube API key here\n",
    "    API_KEY = \"AIzaSyBH-LQhuQMITV7p-Krarbnydkl8J1VhKck\"  # Replace with your actual API key\n",
    "\n",
    "    # Authenticate with YouTube API using the API key\n",
    "    service = get_authenticated_service(API_KEY)\n",
    "\n",
    "    # List of YouTube video IDs\n",
    "    video_ids = [\"TcMBFSGVi1c\", \"eOrNdBpGMv8\"]\n",
    "\n",
    "    total_comments = 1000  # Total number of comments you want across all videos\n",
    "    all_comments = []\n",
    "\n",
    "    # Iterate over each video ID and retrieve comments\n",
    "    for video_id in video_ids:\n",
    "        try:\n",
    "            # Get comments for the specified video with remaining_comments as the limit\n",
    "            comments = get_video_comments(service, video_id, remaining_comments=total_comments)\n",
    "\n",
    "            # Extend the list of all comments with comments from the current video\n",
    "            all_comments.extend(comments)\n",
    "\n",
    "            # Update the total_comments to reflect the remaining\n",
    "            total_comments -= len(comments)\n",
    "\n",
    "            # Exit the loop if the total_comments is fulfilled\n",
    "            if total_comments <= 0:\n",
    "                break\n",
    "\n",
    "        except HttpError as e:\n",
    "            # Handle HTTP errors and print an error message\n",
    "            print(f\"An error occurred for video ID {video_id}: {e}\")\n",
    "\n",
    "    # Convert all comments to a pandas DataFrame\n",
    "    df = pd.DataFrame({\"Comments\": all_comments})\n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(df)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    csv_file_path = \"all_comments.csv\"\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Print a success message with the file path\n",
    "    print(f\"Comments saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27202725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Comments\n",
      "0    The hype for this movie was truly a once in a ...\n",
      "1    The hype for Infinity War and Endgame was unre...\n",
      "2    Today is the 4th year anniversary of endgame's...\n",
      "3    1:40 The way they synced up her gunshots with ...\n",
      "4    This movie really lived up to it's title. It w...\n",
      "..                                                 ...\n",
      "995  Everyone forgot this movie.Because, this movie...\n",
      "996         Avengers  All Series My Favourite All Time\n",
      "997                   mcu should have ended right here\n",
      "998                                 Whatever it takes!\n",
      "999  whatever it takes - It will take the best supe...\n",
      "\n",
      "[1000 rows x 1 columns]\n",
      "Comments saved to all_comments.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the script is being run directly\n",
    "if __name__ == \"__main__\":\n",
    "    # Call the main function to execute the script\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "759d9683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "     ------------------------------------ 636.8/636.8 kB 657.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.5)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fee27948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Comments  Sentiment\n",
      "0    The hype for this movie was truly a once in a ...   0.000000\n",
      "1    The hype for Infinity War and Endgame was unre...   0.000000\n",
      "2    Today is the 4th year anniversary of endgame's...   0.000000\n",
      "3    1:40 The way they synced up her gunshots with ...   0.000000\n",
      "4    This movie really lived up to it's title. It w...   0.200000\n",
      "..                                                 ...        ...\n",
      "995  Everyone forgot this movie.Because, this movie...   0.000000\n",
      "996         Avengers  All Series My Favourite All Time   0.000000\n",
      "997                   mcu should have ended right here   0.285714\n",
      "998                                 Whatever it takes!   0.000000\n",
      "999  whatever it takes - It will take the best supe...   0.666667\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "Comments with sentiment saved to comments_with_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and modules\n",
    "import pandas as pd\n",
    "import googleapiclient.discovery\n",
    "from googleapiclient.errors import HttpError\n",
    "from textblob import TextBlob  # Import TextBlob for sentiment analysis\n",
    "\n",
    "# Function to authenticate with the YouTube API using an API key\n",
    "def get_authenticated_service(api_key):\n",
    "    return googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "\n",
    "# Function to retrieve comments for a YouTube video\n",
    "def get_video_comments(service, video_id, remaining_comments):\n",
    "    comments = []\n",
    "    page_token = None\n",
    "\n",
    "    # Loop until the remaining number of comments is reached\n",
    "    while remaining_comments > 0:\n",
    "        # Adjust maxResults based on the remaining_comments\n",
    "        max_results = min(100, remaining_comments)\n",
    "\n",
    "        kwargs = {\n",
    "            \"part\": \"snippet\",\n",
    "            \"videoId\": video_id,\n",
    "            \"textFormat\": \"plainText\",\n",
    "            \"order\": \"relevance\",\n",
    "            \"maxResults\": max_results,\n",
    "        }\n",
    "\n",
    "        if page_token:\n",
    "            kwargs[\"pageToken\"] = page_token\n",
    "\n",
    "        try:\n",
    "            # Execute the API request to retrieve comments\n",
    "            results = service.commentThreads().list(**kwargs).execute()\n",
    "\n",
    "            # Extract comments from the API response\n",
    "            for item in results.get(\"items\", []):\n",
    "                comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "                comments.append(comment)\n",
    "\n",
    "            # Update the page token for pagination\n",
    "            page_token = results.get(\"nextPageToken\")\n",
    "\n",
    "            # Exit the loop if no more comments are available\n",
    "            if not page_token:\n",
    "                break\n",
    "\n",
    "        except HttpError as e:\n",
    "            # Handle HTTP errors and print an error message\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "        # Update the remaining number of comments\n",
    "        remaining_comments -= max_results\n",
    "\n",
    "    return comments\n",
    "\n",
    "# Function to perform sentiment analysis on a given text\n",
    "def analyze_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "# Main function to execute the YouTube comments retrieval and sentiment analysis\n",
    "def main():\n",
    "    # Set your YouTube API key here\n",
    "    API_KEY = \"AIzaSyBH-LQhuQMITV7p-Krarbnydkl8J1VhKck\"  # Replace with your actual API key\n",
    "\n",
    "    # Authenticate with YouTube API using the API key\n",
    "    service = get_authenticated_service(API_KEY)\n",
    "\n",
    "    # List of YouTube video IDs\n",
    "    video_ids = [\"TcMBFSGVi1c\", \"eOrNdBpGMv8\"]\n",
    "\n",
    "    total_comments = 1000  # Total number of comments you want across all videos\n",
    "    all_comments = []\n",
    "\n",
    "    # Iterate over each video ID and retrieve comments\n",
    "    for video_id in video_ids:\n",
    "        try:\n",
    "            # Get comments for the specified video with remaining_comments as the limit\n",
    "            comments = get_video_comments(service, video_id, remaining_comments=total_comments)\n",
    "\n",
    "            # Extend the list of all comments with comments from the current video\n",
    "            all_comments.extend(comments)\n",
    "\n",
    "            # Update the total_comments to reflect the remaining\n",
    "            total_comments -= len(comments)\n",
    "\n",
    "            # Exit the loop if the total_comments is fulfilled\n",
    "            if total_comments <= 0:\n",
    "                break\n",
    "\n",
    "        except HttpError as e:\n",
    "            # Handle HTTP errors and print an error message\n",
    "            print(f\"An error occurred for video ID {video_id}: {e}\")\n",
    "\n",
    "    # Perform sentiment analysis on each comment\n",
    "    sentiment_scores = [analyze_sentiment(comment) for comment in all_comments]\n",
    "\n",
    "    # Add sentiment scores to the DataFrame\n",
    "    df = pd.DataFrame({\"Comments\": all_comments, \"Sentiment\": sentiment_scores})\n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(df)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    csv_file_path = \"comments_with_sentiment.csv\"\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Print a success message with the file path\n",
    "    print(f\"Comments with sentiment saved to {csv_file_path}\")\n",
    "\n",
    "# Check if the script is being run directly\n",
    "if __name__ == \"__main__\":\n",
    "    # Call the main function to execute the script\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "474ff0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Counts:\n",
      "Neutral     442\n",
      "Positive    434\n",
      "Negative    124\n",
      "Name: Sentiment Category, dtype: int64\n",
      "\n",
      "Comments with Negative Sentiment:\n",
      "23     Ya 4 aÃ±os de esta joya y cronolÃ³gicamente ya s...\n",
      "42     2023, DAN GUE MASIH NONTONIN END GAME BERULANG...\n",
      "75     Even in 2023 still give insane amount of goose...\n",
      "86     Can't believe today is the day we lost Tony Stark\n",
      "87     Unfortunately I couldn't witness this in theat...\n",
      "                             ...                        \n",
      "966    *You sitting on the toilet*\\n\\nToilet paper: *...\n",
      "974     Still think after endgame marvel went south hard\n",
      "975    Avengers assembled,captain america leading,iro...\n",
      "978                           I'm excited for Secret War\n",
      "980        This is where everything started to go wrong.\n",
      "Name: Comments, Length: 124, dtype: object\n",
      "\n",
      "Comments with sentiment saved to comments_with_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and modules\n",
    "import pandas as pd\n",
    "import googleapiclient.discovery\n",
    "from googleapiclient.errors import HttpError\n",
    "from textblob import TextBlob  # Import TextBlob for sentiment analysis\n",
    "\n",
    "# Function to authenticate with the YouTube API using an API key\n",
    "def get_authenticated_service(api_key):\n",
    "    return googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "\n",
    "# Function to retrieve comments for a YouTube video\n",
    "def get_video_comments(service, video_id, remaining_comments):\n",
    "    comments = []\n",
    "    page_token = None\n",
    "\n",
    "    # Loop until the remaining number of comments is reached\n",
    "    while remaining_comments > 0:\n",
    "        # Adjust maxResults based on the remaining_comments\n",
    "        max_results = min(100, remaining_comments)\n",
    "\n",
    "        kwargs = {\n",
    "            \"part\": \"snippet\",\n",
    "            \"videoId\": video_id,\n",
    "            \"textFormat\": \"plainText\",\n",
    "            \"order\": \"relevance\",\n",
    "            \"maxResults\": max_results,\n",
    "        }\n",
    "\n",
    "        if page_token:\n",
    "            kwargs[\"pageToken\"] = page_token\n",
    "\n",
    "        try:\n",
    "            # Execute the API request to retrieve comments\n",
    "            results = service.commentThreads().list(**kwargs).execute()\n",
    "\n",
    "            # Extract comments from the API response\n",
    "            for item in results.get(\"items\", []):\n",
    "                comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "                comments.append(comment)\n",
    "\n",
    "            # Update the page token for pagination\n",
    "            page_token = results.get(\"nextPageToken\")\n",
    "\n",
    "            # Exit the loop if no more comments are available\n",
    "            if not page_token:\n",
    "                break\n",
    "\n",
    "        except HttpError as e:\n",
    "            # Handle HTTP errors and print an error message\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "        # Update the remaining number of comments\n",
    "        remaining_comments -= max_results\n",
    "\n",
    "    return comments\n",
    "\n",
    "# Function to perform sentiment analysis on a given text\n",
    "def analyze_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "# Function to categorize sentiment into positive, negative, or neutral\n",
    "def categorize_sentiment(score):\n",
    "    if score > 0:\n",
    "        return 'Positive'\n",
    "    elif score < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Main function to execute the YouTube comments retrieval and sentiment analysis\n",
    "def main():\n",
    "    # Set your YouTube API key here\n",
    "    API_KEY = \"AIzaSyBH-LQhuQMITV7p-Krarbnydkl8J1VhKck\"  # Replace with your actual API key\n",
    "\n",
    "    # Authenticate with YouTube API using the API key\n",
    "    service = get_authenticated_service(API_KEY)\n",
    "\n",
    "    # List of YouTube video IDs\n",
    "    video_ids = [\"TcMBFSGVi1c\", \"eOrNdBpGMv8\"]\n",
    "\n",
    "    total_comments = 1000  # Total number of comments you want across all videos\n",
    "    all_comments = []\n",
    "\n",
    "    # Iterate over each video ID and retrieve comments\n",
    "    for video_id in video_ids:\n",
    "        try:\n",
    "            # Get comments for the specified video with remaining_comments as the limit\n",
    "            comments = get_video_comments(service, video_id, remaining_comments=total_comments)\n",
    "\n",
    "            # Extend the list of all comments with comments from the current video\n",
    "            all_comments.extend(comments)\n",
    "\n",
    "            # Update the total_comments to reflect the remaining\n",
    "            total_comments -= len(comments)\n",
    "\n",
    "            # Exit the loop if the total_comments is fulfilled\n",
    "            if total_comments <= 0:\n",
    "                break\n",
    "\n",
    "        except HttpError as e:\n",
    "            # Handle HTTP errors and print an error message\n",
    "            print(f\"An error occurred for video ID {video_id}: {e}\")\n",
    "\n",
    "    # Perform sentiment analysis on each comment\n",
    "    sentiment_scores = [analyze_sentiment(comment) for comment in all_comments]\n",
    "\n",
    "    # Categorize sentiments\n",
    "    sentiment_categories = [categorize_sentiment(score) for score in sentiment_scores]\n",
    "\n",
    "    # Add sentiment scores and categories to the DataFrame\n",
    "    df = pd.DataFrame({\"Comments\": all_comments, \"Sentiment Score\": sentiment_scores, \"Sentiment Category\": sentiment_categories})\n",
    "\n",
    "    # Print the counts for each sentiment category\n",
    "    print(\"Sentiment Counts:\")\n",
    "    print(df['Sentiment Category'].value_counts())\n",
    "\n",
    "    # Filter and print only comments with negative sentiment\n",
    "    negative_comments = df[df['Sentiment Category'] == 'Negative']['Comments']\n",
    "    print(\"\\nComments with Negative Sentiment:\")\n",
    "    print(negative_comments)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    csv_file_path = \"comments_with_sentiment.csv\"\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Print a success message with the file path\n",
    "    print(f\"\\nComments with sentiment saved to {csv_file_path}\")\n",
    "\n",
    "# Check if the script is being run directly\n",
    "if __name__ == \"__main__\":\n",
    "    # Call the main function to execute the script\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
